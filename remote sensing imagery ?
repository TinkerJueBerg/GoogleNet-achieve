from __future__ import absolute_import 
from __future__ import division 
from __future__ import print_function  
import codecs   
import os   
import random   
import shutil   
from PIL import Image   
import os 
import numpy as np 
import time 
import math 
import paddle 
import paddle.fluid as fluid 
import codecs 
import logging 
from paddle.fluid.initializer import MSRA 
from paddle.fluid.initializer import Uniform 
from paddle.fluid.param_attr import ParamAttr 
from PIL import Image 
from PIL import ImageEnhance 
import zipfile
import pandas as pd
import colorsys
from numpy import *
import random           


def get_dominant_color(image):
    max_score = 0.0001
    dominant_color = None
    for count,(r,g,b) in image.getcolors(image.size[0]*image.size[1]):
        # 转为HSV标准
        saturation = colorsys.rgb_to_hsv(r/255.0, g/255.0, b/255.0)[1]
        y = min(abs(r*2104+g*4130+b*802+4096+131072)>>13,235)
        y = (y-16.0)/(235-16)
        #忽略高亮色
        if y > 0.9:
            continue
        score = (saturation+0.1)*count
        if score > max_score:
            max_score = score
            dominant_color = (r,g,b)
    return dominant_color
    

def distrop(aim_dir):
    b = np.array([0,0,0]).tolist()
    count_black = 0
    count_same = 0    
    check = 1
    
    
    im1 = Image.open(aim_dir)
    im1 = im1.resize((100,100),Image.ANTIALIAS)
    im1 = np.array(im1).astype(np.float32)
    im1 = im1.tolist()
    
    for i in range(100):
        for j in range(100):
            if im1[i][j] == b:
                count_black += 1
    
    image = Image.open(aim_dir)
    image_array = image.resize((100,100),Image.ANTIALIAS)
    image_array = np.array(image).astype(np.float32)
    main_color = get_dominant_color(image)
#    if __name__ == '__main__':
#        print(main_color)
    for i in range(100):
        for j in range(100):
            if (abs(main_color[0] - image_array[i][j][0]) < 20) and (abs(main_color[1] - image_array[i][j][1]) < 20) and (abs(main_color[2] - image_array[i][j][2]) < 20):
                count_same += 1
    
        if count_black > 2000 or count_same > 8000:
            check = 0
    
        
    return check 
    
    
patht = "/home/aistudio/data/data7071/"
testX = "/home/aistudio/data/data7071/test_image.zip"


ziptestX = zipfile.ZipFile(testX,'r') 
for file in ziptestX.namelist(): 
    ziptestX.extract(file,patht) 
    
path = '/home/aistudio/data/data7071/' 
zip1 = zipfile.ZipFile(patht+'train_images.zip','r') 
zip2 = zipfile.ZipFile(patht+'test_image.zip','r') 
zip3 = zipfile.ZipFile(patht+'Alldata.zip','r')
for file in zip1.namelist(): 
    zip1.extract(file,path) 
for file in zip2.namelist(): 
    zip2.extract(file,path)
for file in zip3.namelist(): 
    zip3.extract(file,path)
print("zipper over")
all_file_dir = 'data/data7071/train_images/train'   

class_list = [c for c in os.listdir(all_file_dir) if os.path.isdir(os.path.join(all_file_dir, c)) and not c.endswith('Set') and not c.startswith('.')]   
class_list.sort() 

for class_dir in class_list:   
    img_paths = os.path.join(all_file_dir, class_dir)  
    for file in os.listdir(img_paths):
        img_pathss = os.path.join(img_paths,file)
        try:
            if distrop(img_pathss) == 0:
                os.remove(img_pathss)
        except:
            pass

#main
train_ratio = 2 / 3   


class_list = [c for c in os.listdir(all_file_dir) if os.path.isdir(os.path.join(all_file_dir, c)) and not c.endswith('Set') and not c.startswith('.')]   
class_list.sort() 
print(class_list)   

train_image_dir = os.path.join(all_file_dir, "trainImageSet")   
if not os.path.exists(train_image_dir):   
    os.makedirs(train_image_dir)   
       
eval_image_dir = os.path.join(all_file_dir, "evalImageSet")   
if not os.path.exists(eval_image_dir):   
    os.makedirs(eval_image_dir)   
   
train_file = codecs.open(os.path.join(all_file_dir, "train.txt"), 'w')   
eval_file = codecs.open(os.path.join(all_file_dir, "eval.txt"), 'w')   
   
with codecs.open(os.path.join(all_file_dir, "label_list.txt"), "w") as label_list:   
    label_id = 0   
    for class_dir in class_list:   
        label_list.write("{0}\t{1}\n".format(label_id, class_dir))   
        image_path_pre = os.path.join(all_file_dir, class_dir)   
        for file in os.listdir(image_path_pre):   
            try:   
                img = Image.open(os.path.join(image_path_pre, file))   
                if random.uniform(0, 1) <= train_ratio:   
                    shutil.copyfile(os.path.join(image_path_pre, file), os.path.join(train_image_dir, file))   
                    train_file.write("{0}\t{1}\n".format(os.path.join(train_image_dir, file), label_id))   
                else:   
                    shutil.copyfile(os.path.join(image_path_pre, file), os.path.join(eval_image_dir, file))   
                    eval_file.write("{0}\t{1}\n".format(os.path.join(eval_image_dir, file), label_id))   
            except Exception as e:   
                pass   
                # 存在一些文件打不开，此处需要稍作清洗   
        label_id += 1   
               
train_file.close()   
eval_file.close()  
print('ALL finished')





train_parameters = {    
    "input_size": [3, 100, 100],    
    "class_dim": -1,  # 分类数，会在初始化自定义 reader 的时候获得    
    "image_count": -1,  # 训练图片数量，会在初始化自定义 reader 的时候获得    
    "label_dict": {},    
    "data_dir": "data/data7071/train_images/train/",  # 训练数据存储地址    
    "train_file_list": "train.txt",    
    "label_file": "label_list.txt",    
    "save_freeze_dir": "./freeze-model",    
    "save_persistable_dir": "./persistable-params",    
    "continue_train": False,        # 是否接着上一次保存的参数接着训练，优先级高于预训练模型    
    "pretrained": True,            # 是否使用预训练的模型    
    "pretrained_dir": "data/data7071/GoogleNet_pretrained",     
    "mode": "train",    
    "num_epochs": 100,    
    "train_batch_size": 400,    
    "mean_rgb": [127.5, 127.5, 127.5],  # 常用图片的三通道均值，通常来说需要先对训练数据做统计，此处仅取中间值    
    "use_gpu": True,    
    "dropout_seed": None,    
    "image_enhance_strategy": {  # 图像增强相关策略    
        "need_distort": True,  # 是否启用图像颜色增强    
        "need_rotate": True,   # 是否需要增加随机角度    
        "need_crop": True,      # 是否要增加裁剪    
        "need_flip": True,      # 是否要增加水平随机翻转    
        "hue_prob": 0.5,    
        "hue_delta": 18,    
        "contrast_prob": 0.5,    
        "contrast_delta": 0.5,    
        "saturation_prob": 0.5,    
        "saturation_delta": 0.5,    
        "brightness_prob": 0.5,    
        "brightness_delta": 0.125  
    },    
    "early_stop": {    
        "sample_frequency": 50,    
        "successive_limit": 3,    
        "good_acc1": 0.92    
    },    
    "rsm_strategy": {    
        "learning_rate": 0.0005,    
        "lr_epochs": [20, 40, 60, 80, 100],    
        "lr_decay": [1, 0.5, 0.25, 0.1, 0.01, 0.002]    
    },    
    "momentum_strategy": {    
        "learning_rate": 0.0005,    
        "lr_epochs": [20, 40, 60, 80, 100],    
        "lr_decay": [1, 0.5, 0.25, 0.1, 0.01, 0.002]    
    },    
    "sgd_strategy": {    
        "learning_rate": 0.0005,    
        "lr_epochs": [20, 40, 60, 80, 100],    
        "lr_decay": [1, 0.5, 0.25, 0.1, 0.01, 0.002]    
    },    
    "adam_strategy": {    
        "learning_rate": 0.00009
    }    
}    
 
class GoogleNet(): 
    def __init__(self): 
        self.params = train_parameters 
 
    def conv_layer(self, 
                   input, 
                   num_filters, 
                   filter_size, 
                   stride=1, 
                   groups=1, 
                   act=None, 
                   name=None): 
        channels = input.shape[1] 
        stdv = (3.0 / (filter_size**2 * channels))**0.5 
        param_attr = ParamAttr( 
            initializer=fluid.initializer.Uniform(-stdv, stdv), 
            name=name + "_weights") 
        conv = fluid.layers.conv2d( 
            input=input, 
            num_filters=num_filters, 
            filter_size=filter_size, 
            stride=stride, 
            padding=(filter_size - 1) // 2, 
            groups=groups, 
            act=act, 
            param_attr=param_attr, 
            bias_attr=False, 
            name=name) 
        return conv 
 
    def xavier(self, channels, filter_size, name): 
        stdv = (3.0 / (filter_size**2 * channels))**0.5 
        param_attr = ParamAttr( 
            initializer=fluid.initializer.Uniform(-stdv, stdv), 
            name=name + "_weights") 
 
        return param_attr 
 
    def inception(self, 
                  input, 
                  channels, 
                  filter1, 
                  filter3R, 
                  filter3, 
                  filter5R, 
                  filter5, 
                  proj, 
                  name=None): 
        conv1 = self.conv_layer( 
            input=input, 
            num_filters=filter1, 
            filter_size=1, 
            stride=1, 
            act=None, 
            name="inception_" + name + "_1x1") 
        conv3r = self.conv_layer( 
            input=input, 
            num_filters=filter3R, 
            filter_size=1, 
            stride=1, 
            act=None, 
            name="inception_" + name + "_3x3_reduce") 
        conv3 = self.conv_layer( 
            input=conv3r, 
            num_filters=filter3, 
            filter_size=3, 
            stride=1, 
            act=None, 
            name="inception_" + name + "_3x3") 
        conv5r = self.conv_layer( 
            input=input, 
            num_filters=filter5R, 
            filter_size=1, 
            stride=1, 
            act=None, 
            name="inception_" + name + "_5x5_reduce") 
        conv5 = self.conv_layer( 
            input=conv5r, 
            num_filters=filter5, 
            filter_size=5, 
            stride=1, 
            act=None, 
            name="inception_" + name + "_5x5") 
        pool = fluid.layers.pool2d( 
            input=input, 
            pool_size=3, 
            pool_stride=1, 
            pool_padding=1, 
            pool_type='max') 
        convprj = fluid.layers.conv2d( 
            input=pool, 
            filter_size=1, 
            num_filters=proj, 
            stride=1, 
            padding=0, 
            name="inception_" + name + "_3x3_proj", 
            param_attr=ParamAttr( 
                name="inception_" + name + "_3x3_proj_weights"), 
            bias_attr=False) 
        cat = fluid.layers.concat(input=[conv1, conv3, conv5, convprj], axis=1) 
        cat = fluid.layers.relu(cat) 
        return cat 
    def generalization_para(input):
        
        omega = random.uniform(0.7,0.95)
        input = mutiply(input,omega)
        return input
    
    def net(self, input, class_dim=1000): 
        
        ge_input = generalization_para(input)
        conv = self.conv_layer( 
            input=ge_input, 
            num_filters=64, 
            filter_size=7, 
            stride=2, 
            act=None, 
            name="conv1") 
        pool = fluid.layers.pool2d( 
            input=conv, pool_size=3, pool_type='max', pool_stride=2) 
 
        conv = self.conv_layer( 
            input=pool, 
            num_filters=64, 
            filter_size=1, 
            stride=1, 
            act=None, 
            name="conv2_1x1") 
        conv = self.conv_layer( 
            input=conv, 
            num_filters=192, 
            filter_size=3, 
            stride=1, 
            act=None, 
            name="conv2_3x3") 
        pool = fluid.layers.pool2d( 
            input=conv, pool_size=3, pool_type='max', pool_stride=2) 
 
        ince3a = self.inception(pool, 192, 64, 96, 128, 16, 32, 32, "ince3a") 
        ince3b = self.inception(ince3a, 256, 128, 128, 192, 32, 96, 64, 
                                "ince3b") 
        pool3 = fluid.layers.pool2d( 
            input=ince3b, pool_size=3, pool_type='max', pool_stride=2) 
 
        ince4a = self.inception(pool3, 480, 192, 96, 208, 16, 48, 64, "ince4a") 
        ince4b = self.inception(ince4a, 512, 160, 112, 224, 24, 64, 64, 
                                "ince4b") 
        ince4c = self.inception(ince4b, 512, 128, 128, 256, 24, 64, 64, 
                                "ince4c") 
        ince4d = self.inception(ince4c, 512, 112, 144, 288, 32, 64, 64, 
                                "ince4d") 
        ince4e = self.inception(ince4d, 528, 256, 160, 320, 32, 128, 128, 
                                "ince4e") 
        pool4 = fluid.layers.pool2d( 
            input=ince4e, pool_size=3, pool_type='max', pool_stride=2) 
 
        ince5a = self.inception(pool4, 832, 256, 160, 320, 32, 128, 128, 
                                "ince5a") 
        ince5b = self.inception(ince5a, 832, 384, 192, 384, 48, 128, 128, 
                                "ince5b") 
        pool5 = fluid.layers.pool2d( 
            input=ince5b, pool_size=7, pool_type='avg', pool_stride=7) 
        dropout = fluid.layers.dropout(x=pool5, dropout_prob=0.4) 
        out = fluid.layers.fc(input=dropout, 
                              size=class_dim, 
                              act='softmax', 
                              param_attr=self.xavier(1024, 1, "out"), 
                              name="out", 
                              bias_attr=ParamAttr(name="out_offset")) 
 
        pool_o1 = fluid.layers.pool2d( 
            input=ince4a, pool_size=5, pool_type='avg', pool_stride=3) 
        conv_o1 = self.conv_layer( 
            input=pool_o1, 
            num_filters=128, 
            filter_size=1, 
            stride=1, 
            act=None, 
            name="conv_o1") 
        fc_o1 = fluid.layers.fc(input=conv_o1, 
                                size=1024, 
                                act='relu', 
                                param_attr=self.xavier(2048, 1, "fc_o1"), 
                                name="fc_o1", 
                                bias_attr=ParamAttr(name="fc_o1_offset")) 
        dropout_o1 = fluid.layers.dropout(x=fc_o1, dropout_prob=0.7) 
        out1 = fluid.layers.fc(input=dropout_o1, 
                               size=class_dim, 
                               act='softmax', 
                               param_attr=self.xavier(1024, 1, "out1"), 
                               name="out1", 
                               bias_attr=ParamAttr(name="out1_offset")) 
 
        pool_o2 = fluid.layers.pool2d( 
            input=ince4d, pool_size=5, pool_type='avg', pool_stride=3) 
        conv_o2 = self.conv_layer( 
            input=pool_o2, 
            num_filters=128, 
            filter_size=1, 
            stride=1, 
            act=None, 
            name="conv_o2") 
        fc_o2 = fluid.layers.fc(input=conv_o2, 
                                size=1024, 
                                act='relu', 
                                param_attr=self.xavier(2048, 1, "fc_o2"), 
                                name="fc_o2", 
                                bias_attr=ParamAttr(name="fc_o2_offset")) 
        dropout_o2 = fluid.layers.dropout(x=fc_o2, dropout_prob=0.7) 
        out2 = fluid.layers.fc(input=dropout_o2, 
                               size=class_dim, 
                               act='softmax', 
                               param_attr=self.xavier(1024, 1, "out2"), 
                               name="out2", 
                               bias_attr=ParamAttr(name="out2_offset")) 
 
        # last fc layer is "out" 
        return out, out1, out2 
 
 
def init_log_config(): 
    """ 
    初始化日志相关配置 
    :return: 
    """ 
    global logger 
    logger = logging.getLogger() 
    logger.setLevel(logging.INFO) 
    log_path = os.path.join(os.getcwd(), 'logs') 
    if not os.path.exists(log_path): 
        os.makedirs(log_path) 
    log_name = os.path.join(log_path, 'train.log') 
    sh = logging.StreamHandler() 
    fh = logging.FileHandler(log_name, mode='w') 
    fh.setLevel(logging.DEBUG) 
    formatter = logging.Formatter("%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s") 
    fh.setFormatter(formatter) 
    sh.setFormatter(formatter) 
    logger.addHandler(sh) 
    logger.addHandler(fh) 
 
 
def init_train_parameters(): 
    """ 
    初始化训练参数，主要是初始化图片数量，类别数 
    :return: 
    """ 
    train_file_list = os.path.join(train_parameters['data_dir'], train_parameters['train_file_list']) 
    label_list = os.path.join(train_parameters['data_dir'], train_parameters['label_file']) 
    index = 0 
    with codecs.open(label_list, encoding='utf-8') as flist: 
        lines = [line.strip() for line in flist] 
        for line in lines: 
            parts = line.strip().split() 
            train_parameters['label_dict'][parts[1]] = int(parts[0]) 
            index += 1 
        train_parameters['class_dim'] = index 
    with codecs.open(train_file_list, encoding='utf-8') as flist: 
        lines = [line.strip() for line in flist] 
        train_parameters['image_count'] = len(lines) 
 
 
def resize_img(img, target_size): 
    """ 
    强制缩放图片 
    :param img: 
    :param target_size: 
    :return: 
    """ 
    target_size = input_size 
    img = img.resize((target_size[1], target_size[2]), Image.BILINEAR) 
    return img 
 
 
def random_crop(img, scale=[0.08, 1.0], ratio=[3. / 4., 4. / 3.]): 
    aspect_ratio = math.sqrt(np.random.uniform(*ratio)) 
    w = 1. * aspect_ratio 
    h = 1. / aspect_ratio 
 
    bound = min((float(img.size[0]) / img.size[1]) / (w**2), 
                (float(img.size[1]) / img.size[0]) / (h**2)) 
    scale_max = min(scale[1], bound) 
    scale_min = min(scale[0], bound) 
 
    target_area = img.size[0] * img.size[1] * np.random.uniform(scale_min, 
                                                                scale_max) 
    target_size = math.sqrt(target_area) 
    w = int(target_size * w) 
    h = int(target_size * h) 
 
    i = np.random.randint(0, img.size[0] - w + 1) 
    j = np.random.randint(0, img.size[1] - h + 1) 
 
    img = img.crop((i, j, i + w, j + h)) 
    img = img.resize((train_parameters['input_size'][1], train_parameters['input_size'][2]), Image.BILINEAR) 
    return img 
 
 
def rotate_image(img): 
    """ 
    图像增强，增加随机旋转角度 
    """ 
    angle = np.random.randint(-14, 15) 
    img = img.rotate(angle) 
    return img 
 
 
def random_brightness(img): 
    """ 
    图像增强，亮度调整 
    :param img: 
    :return: 
    """ 
    prob = np.random.uniform(0, 1) 
    if prob < train_parameters['image_enhance_strategy']['brightness_prob']: 
        brightness_delta = train_parameters['image_enhance_strategy']['brightness_delta'] 
        delta = np.random.uniform(-brightness_delta, brightness_delta) + 1 
        img = ImageEnhance.Brightness(img).enhance(delta) 
    return img 
 
 
def random_contrast(img): 
    """ 
    图像增强，对比度调整 
    :param img: 
    :return: 
    """ 
    prob = np.random.uniform(0, 1) 
    if prob < train_parameters['image_enhance_strategy']['contrast_prob']: 
        contrast_delta = train_parameters['image_enhance_strategy']['contrast_delta'] 
        delta = np.random.uniform(-contrast_delta, contrast_delta) + 1 
        img = ImageEnhance.Contrast(img).enhance(delta) 
    return img 
 
 
def random_saturation(img): 
    """ 
    图像增强，饱和度调整 
    :param img: 
    :return: 
    """ 
    prob = np.random.uniform(0, 1) 
    if prob < train_parameters['image_enhance_strategy']['saturation_prob']: 
        saturation_delta = train_parameters['image_enhance_strategy']['saturation_delta'] 
        delta = np.random.uniform(-saturation_delta, saturation_delta) + 1 
        img = ImageEnhance.Color(img).enhance(delta) 
    return img 
 
 
def random_hue(img): 
    """ 
    图像增强，色度调整 
    :param img: 
    :return: 
    """ 
    prob = np.random.uniform(0, 1) 
    if prob < train_parameters['image_enhance_strategy']['hue_prob']: 
        hue_delta = train_parameters['image_enhance_strategy']['hue_delta'] 
        delta = np.random.uniform(-hue_delta, hue_delta) 
        img_hsv = np.array(img.convert('HSV')) 
        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta 
        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB') 
    return img 
 
 
def distort_color(img): 
    """ 
    概率的图像增强 
    :param img: 
    :return: 
    """ 
    prob = np.random.uniform(0, 1) 
    # Apply different distort order 
    if prob < 0.35: 
        img = random_brightness(img) 
        img = random_contrast(img) 
        img = random_saturation(img) 
        img = random_hue(img) 
    elif prob < 0.7: 
        img = random_brightness(img) 
        img = random_saturation(img) 
        img = random_hue(img) 
        img = random_contrast(img) 
    return img 
 
 
def custom_image_reader(file_list, data_dir, mode): 
    """ 
    自定义用户图片读取器，先初始化图片种类，数量 
    :param file_list: 
    :param data_dir: 
    :param mode: 
    :return: 
    """ 
    with codecs.open(file_list) as flist: 
        lines = [line.strip() for line in flist] 
 
    def reader(): 
        np.random.shuffle(lines) 
        for line in lines: 
            if mode == 'train' or mode == 'val': 
                img_path, label = line.split() 
                img = Image.open(img_path) 
                try: 
                    if img.mode != 'RGB': 
                        img = img.convert('RGB') 
                    if train_parameters['image_enhance_strategy']['need_distort'] == True: 
                        img = distort_color(img) 
                    if train_parameters['image_enhance_strategy']['need_rotate'] == True: 
                        img = rotate_image(img) 
                    if train_parameters['image_enhance_strategy']['need_crop'] == True: 
                        img = random_crop(img, train_parameters['input_size']) 
                    if train_parameters['image_enhance_strategy']['need_flip'] == True: 
                        mirror = int(np.random.uniform(0, 2)) 
                        if mirror == 1: 
                            img = img.transpose(Image.FLIP_LEFT_RIGHT) 
                    # HWC--->CHW && normalized 
                    img = np.array(img).astype('float32') 
                    img -= train_parameters['mean_rgb'] 
                    img = img.transpose((2, 0, 1))  # HWC to CHW 
                    img *= 0.007843                 # 像素值归一化 
                    yield img, int(label) 
                except Exception as e: 
                    pass                            # 以防某些图片读取处理出错，加异常处理 
            elif mode == 'test': 
                img_path = os.path.join(data_dir, line) 
                img = Image.open(img_path) 
                if img.mode != 'RGB': 
                    img = img.convert('RGB') 
                img = resize_img(img, train_parameters['input_size']) 
                # HWC--->CHW && normalized 
                img = np.array(img).astype('float32') 
                img -= train_parameters['mean_rgb'] 
                img = img.transpose((2, 0, 1))  # HWC to CHW 
                img *= 0.007843  # 像素值归一化 
                yield img 
 
    return reader 
 
 
def optimizer_momentum_setting(): 
    """ 
    阶梯型的学习率适合比较大规模的训练数据 
    """ 
    learning_strategy = train_parameters['momentum_strategy'] 
    batch_size = train_parameters["train_batch_size"] 
    iters = train_parameters["image_count"] // batch_size 
    lr = learning_strategy['learning_rate'] 
 
    boundaries = [i * iters for i in learning_strategy["lr_epochs"]] 
    values = [i * lr for i in learning_strategy["lr_decay"]] 
    learning_rate = fluid.layers.piecewise_decay(boundaries, values) 
    optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9) 
    return optimizer 
 
 
def optimizer_rms_setting(): 
    """ 
    阶梯型的学习率适合比较大规模的训练数据 
    """ 
    batch_size = train_parameters["train_batch_size"] 
    iters = train_parameters["image_count"] // batch_size 
    learning_strategy = train_parameters['rsm_strategy'] 
    lr = learning_strategy['learning_rate'] 
 
    boundaries = [i * iters for i in learning_strategy["lr_epochs"]] 
    values = [i * lr for i in learning_strategy["lr_decay"]] 
 
    optimizer = fluid.optimizer.RMSProp( 
        learning_rate=fluid.layers.piecewise_decay(boundaries, values)) 
 
    return optimizer 
 
 
def optimizer_sgd_setting(): 
    """ 
    loss下降相对较慢，但是最终效果不错，阶梯型的学习率适合比较大规模的训练数据 
    """ 
    learning_strategy = train_parameters['sgd_strategy'] 
    batch_size = train_parameters["train_batch_size"] 
    iters = train_parameters["image_count"] // batch_size 
    lr = learning_strategy['learning_rate'] 
 
    boundaries = [i * iters for i in learning_strategy["lr_epochs"]] 
    values = [i * lr for i in learning_strategy["lr_decay"]] 
    learning_rate = fluid.layers.piecewise_decay(boundaries, values) 
    optimizer = fluid.optimizer.SGD(learning_rate=learning_rate) 
    return optimizer 
 
 
def optimizer_adam_setting(): 
    """ 
    能够比较快速的降低 loss，但是相对后期乏力 
    """ 
    learning_strategy = train_parameters['adam_strategy'] 
    learning_rate = learning_strategy['learning_rate'] 
    optimizer = fluid.optimizer.Adam(learning_rate=learning_rate) 
    return optimizer 
 
 
def load_params(exe, program): 
    if train_parameters['continue_train'] and os.path.exists(train_parameters['save_persistable_dir']): 
        logger.info('load params from retrain model') 
        fluid.io.load_persistables(executor=exe, 
                                   dirname=train_parameters['save_persistable_dir'], 
                                   main_program=program) 
    elif train_parameters['pretrained'] and os.path.exists(train_parameters['pretrained_dir']): 
        logger.info('load params from pretrained model') 
        def if_exist(var): 
            return os.path.exists(os.path.join(train_parameters['pretrained_dir'], var.name)) 
 
        fluid.io.load_vars(exe, train_parameters['pretrained_dir'], main_program=program, 
                           predicate=if_exist) 
 
 
def train(): 
    train_prog = fluid.Program() 
    train_startup = fluid.Program() 
    logger.info("create prog success") 
    logger.info("train config: %s", str(train_parameters)) 
    logger.info("build input custom reader and data feeder") 
    file_list = os.path.join(train_parameters['data_dir'], "train.txt") 
    mode = train_parameters['mode'] 
    batch_reader = paddle.batch(custom_image_reader(file_list, train_parameters['data_dir'], mode), 
                                batch_size=train_parameters['train_batch_size'], 
                                drop_last=False) 
    batch_reader = paddle.reader.shuffle(batch_reader, train_parameters['train_batch_size']) 
    place = fluid.CUDAPlace(0) if train_parameters['use_gpu'] else fluid.CPUPlace() 
    # 定义输入数据的占位符 
    img = fluid.layers.data(name='img', shape=train_parameters['input_size'], dtype='float32') 
    label = fluid.layers.data(name='label', shape=[1], dtype='int64') 
    feeder = fluid.DataFeeder(feed_list=[img, label], place=place) 
 
    # 选取不同的网络 
    logger.info("build newwork") 
    model = GoogleNet() 
    out, out1, out2 = model.net(input=img, class_dim=train_parameters['class_dim']) 
    cost0 = fluid.layers.cross_entropy(input=out, label=label) 
    cost1 = fluid.layers.cross_entropy(input=out1, label=label) 
    cost2 = fluid.layers.cross_entropy(input=out2, label=label) 
    avg_cost0 = fluid.layers.mean(x=cost0) 
    avg_cost1 = fluid.layers.mean(x=cost1) 
    avg_cost2 = fluid.layers.mean(x=cost2) 
 
    avg_cost = avg_cost0 + 0.3 * avg_cost1 + 0.3 * avg_cost2 
    acc_top1 = fluid.layers.accuracy(input=out, label=label, k=1) 
    # 选取不同的优化器 
    #optimizer = optimizer_rms_setting() 
    # optimizer = optimizer_momentum_setting() 
    #optimizer = optimizer_sgd_setting() 
    optimizer = optimizer_adam_setting() 
    optimizer.minimize(avg_cost) 
    exe = fluid.Executor(place) 
 
    main_program = fluid.default_main_program() 
    exe.run(fluid.default_startup_program()) 
    train_fetch_list = [avg_cost.name, acc_top1.name, out.name] 
     
    load_params(exe, main_program) 
 
    # 训练循环主体 
    stop_strategy = train_parameters['early_stop'] 
    successive_limit = stop_strategy['successive_limit'] 
    sample_freq = stop_strategy['sample_frequency'] 
    good_acc1 = stop_strategy['good_acc1'] 
    successive_count = 0 
    stop_train = False 
    total_batch_count = 0 
    for pass_id in range(train_parameters["num_epochs"]): 
        logger.info("current pass: %d, start read image", pass_id) 
        batch_id = 0 
        for step_id, data in enumerate(batch_reader()): 
            t1 = time.time() 
            loss, acc1, pred_ot = exe.run(main_program, 
                                          feed=feeder.feed(data), 
                                          fetch_list=train_fetch_list) 
            t2 = time.time() 
            batch_id += 1 
            total_batch_count += 1 
            period = t2 - t1 
            loss = np.mean(np.array(loss)) 
            acc1 = np.mean(np.array(acc1)) 
            if batch_id % 50 == 0: 
                logger.info("Pass {0}, trainbatch {1}, loss {2}, acc1 {3}, time {4}".format(pass_id, batch_id, loss, acc1, 
                                                                                            "%2.2f sec" % period)) 
            # 简单的提前停止策略，认为连续达到某个准确率就可以停止了 
            if acc1 >= good_acc1: 
                successive_count += 1 
                logger.info("current acc1 {0} meets good {1}, successive count {2}".format(acc1, good_acc1, successive_count)) 
                fluid.io.save_inference_model(dirname=train_parameters['save_freeze_dir'], 
                                              feeded_var_names=['img'], 
                                              target_vars=[out], 
                                              main_program=main_program, 
                                              executor=exe) 
                if successive_count >= successive_limit: 
                    logger.info("end training") 
                    stop_train = True 
                    break 
            else: 
                successive_count = 0 
 
            # 通用的保存策略，减小意外停止的损失 
            if total_batch_count % sample_freq == 0: 
                logger.info("temp save {0} batch train result, current acc1 {1}".format(total_batch_count, acc1)) 
                fluid.io.save_persistables(dirname=train_parameters['save_persistable_dir'], 
                                           main_program=main_program, 
                                           executor=exe) 
        if stop_train: 
            break 
    logger.info("training till last epcho, end training") 
    fluid.io.save_persistables(dirname=train_parameters['save_persistable_dir'], 
                                           main_program=main_program, 
                                           executor=exe) 
    fluid.io.save_inference_model(dirname=train_parameters['save_freeze_dir'], 
                                              feeded_var_names=['img'], 
                                              target_vars=[out], 
                                              main_program=main_program.clone(for_test=True), 
                                              executor=exe) 



if __name__ == '__main__': 
    init_log_config() 
    init_train_parameters() 
    train() 
  
    
    
target_size = [3, 100, 100]     
mean_rgb = [127.5, 127.5, 127.5]     
data_dir = "data/data7071/train_images/train"     
eval_file = "eval.txt"     
use_gpu = True     
place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()     
exe = fluid.Executor(place)     
save_freeze_dir = "./freeze-model"     
[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(dirname=save_freeze_dir, executor=exe)     
# print(fetch_targets)     
     
     
def crop_image(img, target_size):     
    width, height = img.size     
    w_start = (width - target_size[2]) / 2     
    h_start = (height - target_size[1]) / 2     
    w_end = w_start + target_size[2]     
    h_end = h_start + target_size[1]     
    img = img.crop((w_start, h_start, w_end, h_end))     
    return img     
     
     
def resize_img(img, target_size):     
    ret = img.resize((target_size[1], target_size[2]), Image.BILINEAR)     
    return ret     
     
     
def read_image(img_path):     
    img = Image.open(img_path)     
    if img.mode != 'RGB':     
        img = img.convert('RGB')     
    img = crop_image(img, target_size)     
    img = np.array(img).astype('float32')     
    img -= mean_rgb     
    img = img.transpose((2, 0, 1))  # HWC to CHW     
    img *= 0.007843     
    img = img[np.newaxis,:]     
    return img     
     
     
def infer(image_path):     
    tensor_img = read_image(image_path)     
    label = exe.run(inference_program, feed={feed_target_names[0]: tensor_img}, fetch_list=fetch_targets)     
    return np.argmax(label)     
     
     
def eval_all():     
    eval_file_path = os.path.join(data_dir, eval_file)     
    total_count = 0     
    right_count = 0     
    with codecs.open(eval_file_path, encoding='utf-8') as flist:      
        lines = [line.strip() for line in flist]     
        t1 = time.time()     
        for line in lines:     
            total_count += 1     
            parts = line.strip().split()     
            result = infer(parts[0])     
            # print("infer result:{0} answer:{1}".format(result, parts[1]))     
            if str(result) == parts[1]:     
                right_count += 1     
        period = time.time() - t1     
        print("total eval count:{0} cost time:{1} predict accuracy:{2}".format(total_count, "%2.2f sec" % period, right_count / total_count))     
  
     
if __name__ == '__main__':     
    eval_all()   
    
print("Mission Completed")



test_image_dir = "/home/aistudio/data/data7071/test_image/"     


train_image_dir = "/home/aistudio/data/data7071/Alldata/"
for file in os.listdir(train_image_dir): 
    img_train = Image.open(os.path.join(train_image_dir, file)) 
    
    
train_image_dir = "/home/aistudio/data/data7071/Alldata/"
label=[]
for file in os.listdir(train_image_dir):
    label.append(file.split('_')[1].split('.')[0])

saved_path='freeze-model/'
predictions_s = []


def load_image(file):
	im=Image.open(file)
	im=im.resize((100,100),Image.ANTIALIAS)
	im=np.array(im).astype(np.float32)
	#PIL打开图片存储顺序为H（高度），W（宽度），C（通道数）
	#但是PaddlePaddle要求数据的顺序是CHW，需要调整顺序
	im=im.transpose((2,0,1))
	#cifar训练的图片通道顺序为B(蓝)，G(绿)，R(红)
	#但是PIL打开的图片是默认的RGB，所以要交换通道
	#im=im[(2,1,0),:,:]
	#im=im/255.0#归一化
	im=np.expand_dims(im,axis=0)
	return im

 
Functions_area = ['Residential area','School','Industrial park','Railway station','Airport','Park','Shopping area','Administrative district','Hospital']

def test():
    # 是否使用GPU
    # 是否使用GPU
    place = fluid.CUDAPlace(0) if train_parameters['use_gpu'] else fluid.CPUPlace()
    # 生成调试器
    exe = fluid.Executor(place)
    exe.run(fluid.default_startup_program())
    
    inference_scope = fluid.core.Scope()
    
        # 加载模型
    [inference_program, feed_target_names,fetch_targets] = fluid.io.load_inference_model(dirname=saved_path,executor=exe)

    names=['001','002','003','004','005','006','007','008','009']
    based_dir = 'data/data7071/test_image/'
    i = 0
    for file in os.listdir(based_dir): 
        select_pic = load_image(os.path.join(based_dir,file))
        results = exe.run(program=inference_program,
                      feed={feed_target_names[0]:select_pic },
                      fetch_list=fetch_targets)
        lab = np.argmax(results[0][0]) 
        #lab = int(lab)
        i += 1
        predictions_s.append(names[lab])
        #print(results[0][0][lab])
        print("第n个:%s,预测的标签是：%d,名称是：%s,概率是：%f"%(i,lab,names[lab],results[0][0][lab]))
test()

predictions_s = np.array(predictions_s).reshape(-1,1)

areaid = np.arange (0,10000).reshape(-1,1)
#print(prediction,areaid)

Stackingmerge = np.c_[areaid,predictions_s]
StackingCsv = pd.DataFrame(Stackingmerge)
StackingCsv.columns = ['areaid','categoryid']
StackingCsv.to_csv('Satellitebc.csv',index=False,sep=',')
print("over")
